# **Fandom Hypergraph**

### **Описание датасета**

Проект посвящён извлечению и структурированию информации из вики-сообществ Fandom. В качестве примера используется вики по вселенной *Fallout: New Vegas* ([пример статьи](https://fallout.fandom.com/wiki/New_California_Republic)).

Каждая статья парсится, разбивается на смысловые фрагменты (чанки), из которых извлекается текст и список ссылок на другие страницы этого же фандома. Эти связи сохраняются, чтобы впоследствии можно было понять, какие статьи ссылаются друг на друга.

Каждая запись в итоговом датасете содержит:

* `document_id` — уникальный ID страницы (например, slug URL);
* `chunk_id` — номер чанка в пределах статьи;
* `title` — заголовок статьи;
* `chunk_text` — текст чанка;
* `outgoing_links` — список ссылок (URL или slug), на которые ссылается этот чанк;
* `source` — исходная ссылка на статью;
* `comment` — дополнительные пометки (опционально).

**Формат таблицы:**

```
document_id | chunk_id | title | chunk_text | outgoing_links | source | comment
```

---

### **Задание: что нужно сделать**

1. **Сбор данных из Fandom API**

   * Настроить парсер, используя [официальный API Fandom](https://wikies.fandom.com/wiki/API), для получения статей по заданному фандому.
   * В качестве примера можно взять вики по Fallout: New Vegas ([пример страницы](https://fallout.fandom.com/wiki/New_California_Republic)).

2. **Обработка текста**

   * Распарсить HTML-содержимое и извлечь основной текст.
   * Разбить текст на чанки с перекрытием (например, 300–500 слов).
   * Для этого можно использовать [LangChain Document Transformers](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/).

3. **Извлечение связей**

   * Для каждого чанка сохранить ссылки на другие статьи (внутренние гиперссылки).
   * Составить для каждой страницы список документов, на которые она явно ссылается.

4. **Формирование таблицы**

   * Уложить данные в CSV/JSONL с полями, описанными выше.
   * Структура должна быть пригодна для дальнейшего анализа, фильтрации и визуализации.

5. **Построение дашборда**

   * Реализовать дашборд в **Streamlit**, который позволяет:

     * искать статьи и смотреть их текст по чанкам;
     * видеть список ссылок, на которые ссылается статья;
     * фильтровать и сортировать статьи по количеству ссылок и чанков;
     * отображать базовую статистику: количество документов, средняя длина чанка, число ссылок и т.д.

---

### **Конечный результат**

* Обогащённый датасет по вики-сообществу Fandom, содержащий тексты и ссылки между статьями;
* Парсер с возможностью обрабатывать любые вики-сообщества на платформе Fandom;
* Гибкая система разбиения текста на чанки;
* Простой интерактивный дашборд на **Streamlit** для анализа полученных данных;
* Возможность масштабировать парсер под другие вики без дополнительных изменений кода.
